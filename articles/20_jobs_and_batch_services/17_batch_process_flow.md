# **Fabric Batch Processes Architecture**

## **Fabric Batch Processes Flow**  

The following activities are automatically triggered when a new Batch process is executed:
-  A new Batch entry is added in Cassandra.
-  A new Job entry is recorded in also the k2system_jobs table with the following parameters:
   
   -  Name = the name of the Batch process.
   -  Type = BATCH PROCESS.
   
-  The WAITING_FOR_JOB status is then assigned to the Batch process.  

After this, any available node, or any node whose affinity has been specified in the Batch command, handles the execution of the Job and of the subcommand as specified in the Batch command.

Once the corresponding Job begins, and is set to an **IN_PROCESS** stage, the Batch process undergoes the following stages:
1. NEW
2. GENERATE_IID
3. IN_PROGRESS
4. FAILED/CANCELLED/DONE


The illustration below shows how, once triggered from the command line, an asynchronous batch process is automatically encapsulated into a Job process. 

The Job Process then launches the batch command which, in turn, is executed through its lifecycle phases. 
 
<img src="/articles/20_jobs_and_batch_services/images/13_jobs_and_batch_services_batch_process.PNG">



## **Scheduling Batch Processes**


To schedule a Batch process to be executed either at a given time or recurrently, a scheduled Job process must be created, using a user job, containing the batch command that needs to be repeatedly invoked. 

This consists in creating a Job that calls a Batch process which in turn creates multiple or scheduled one-time Jobs (each one parametered with the execution settings parsed in the Batch command).

<img src="/articles/20_jobs_and_batch_services/images/14_jobs_and_batch_services_scheduled_batch_process.PNG">

 

## **Batch Process Table in Cassandra**
All batch-related information is displayed in the **k2batchprocess** keyspace in the **batchprocess_list** table.

### Example 

```cassandra@cqlsh:k2batchprocess> select * from batchprocess_list;```


<table width="900pxl">
<tbody>
<tr>
<td valign="top" width="300pxl">
<p><strong>Field</strong></p>
</td>
<td valign="top" width="400pxl">
<p><strong>Value</strong></p>
</td>
<td valign="top" width="400pxl">
<p><strong>Description</strong></p>
</td>

</tr>
<tr>
<td valign="top" width="300pxl">
<p><strong>bid</strong></p>
</td>
<td valign="top" width="400pxl">
<p>35408af6-b26a-4243-bc95-f114335bfa5e</p>
</td>
<td valign="top" width="400pxl">
<p>Unique ID generated by the system upon batch execution.</p>
</td>
 
 
</tr>
<tr>
<td valign="top" width="300pxl">
<p><strong>creation_time</strong></p>
</td>
<td valign="top" width="400pxl">
<p>2020-08-12 12:20:07.894000+0000</p>
</td>
<td valign="top" width="400pxl">
<p>Timestamp of when the Batch process was created.</p>
</td>
</tr>

<tr>
<td valign="top" width="300pxl">
<p><strong>end_time</strong></p>
</td>
<td valign="top" width="400pxl">
<p>2020-08-12 12:20:09.176000+0000</p>
</td>
<td valign="top" width="400pxl">
<p>Timestamp of when the Batch process ended.</p>
</td>
</tr>

<tr>
<td valign="top" width="300pxl">
<p><strong>lut_name</strong></p>
</td>
<td valign="top" width="400pxl">
<p>AUTODATA_DELTA</p>
</td>
<td valign="top" width="400pxl">
<p>Name of the LUT recieving the instances.</p>
</td>
</tr>


<tr>
<td valign="top" width="300pxl">
<p><strong>start_time</strong></p>
</td>
<td valign="top" width="400pxl">
<p>2020-08-12 12:20:07.907000+0000</p>
</td>
<td valign="top" width="400pxl">
<p>Timestamp of when the Batch process started.</p>
</td>
</tr>


<tr>
<td valign="top" width="300pxl">
<p><strong>status</strong></p>
</td>
<td valign="top" width="400pxl">
<p>Done</p>
</td>
<td valign="top" width="400pxl">
<p>Stage of the Batch process.</p>
</td>
</tr>


<tr>
<td valign="top" width="300pxl">
<p><strong>total_entities</strong></p>
</td>
<td valign="top" width="400pxl">
<p>200</p>
</td>
<td valign="top" width="400pxl">
<p>Number of entities processed.</p>
</td>
</tr>

</tbody>
</table>


**Command**  

```
BATCH AUTODATA_DELTA FROM idsFile USING ('select id from ids  limit 100') FABRIC_COMMAND="sync_instance AUTODATA_DELTA.?" with JOB_AFFINITY='10.21.2.102' ASYNC='true';
```

In this case the command describes a synchronization process of a list of IDs with affinity set to Node: 10.21.2.102 


**extra_stats**  

This field shows the slowest-processed entities, along with their ID, processing time, status, and fields changes: 

```
{"slowestProcessed":[{"entityId":"4","processTimeMS":572,"status":"COMPLETED","result":"{\"Added\":1,\"Updated\":0,\"Unchanged\":0}"},{"entityId":"5","processTimeMS":573,"status":"COMPLETED","result":"{\"Added\":1,\"Updated\":0,\"Unchanged\":0}"},{"entityId":"47","processTimeMS":645,"status":"COMPLETED","result":"{\"Added\":1,\"Updated\":0,\"Unchanged\":0}"}
```




## **Batch Process Execution & Resiliency**


When executed asynchrounously (*async* flag set to *true*), the batch process inherits from the Jobs ability to transfer the process to a different node when a node is no longer active or no longer responding. 

This handover mechanism uses the [*hearbeats*](/articles/20_jobs_and_batch_services/09_jobs_configuration.md#heartbeat) and [*keepalive*](/articles/20_jobs_and_batch_services/09_jobs_configuration.md#keepalive) parameters defined within the node.id file.

The next handling node picks up the batch process (via its associated job) and resumes its execution from the latest known recorded stage.   

Each Fabric node uses its Fabric built-in BatchProcessAPI and [Job Manager](/articles/20_jobs_and_batch_services/02_jobs_flow_and_status.md#jobs-logic) classes to manage the Batch process through its different lifecycle stages, as defined in the illustrations above.



[![Previous](/articles/images/Previous.png)](/articles/20_jobs_and_batch_services/15_batch_CDC_commands.md)



